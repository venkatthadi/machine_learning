{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google_play_scraper import reviews, reviews_all\n",
    "from google_play_scraper import Sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "apps = {\n",
    "    \"Mobicip\" : \"mobicip.com.safeBrowserff\",\n",
    "    \"Google Family Link\" : \"com.google.android.apps.kids.familylink\",\n",
    "    \"Net Nanny\" : \"com.contentwatch.ghoti.cp2.parent\",\n",
    "    \"Kaspersky SafeKids\" : \"com.kaspersky.safekids\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort = Sort.NEWEST\n",
    "n_reviews = 10000\n",
    "reviews_dict = {k : {} for k in apps}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in apps.keys():\n",
    "        reviews_dict[app] = reviews_all(\n",
    "                apps[app],\n",
    "                lang = 'en',\n",
    "                sleep_milliseconds=0,\n",
    "                country = 'us',\n",
    "                sort = sort,\n",
    "                count = n_reviews,\n",
    "                filter_score_with = None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reviews_dict['Mobicip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for app in apps.keys():\n",
    "        SAVE_DIR = app + '.csv'\n",
    "        temp_df = pd.DataFrame(\n",
    "                reviews_dict[app],\n",
    "                columns = ['reviewId', 'userName', 'content', 'score'] \n",
    "        )\n",
    "        temp_df.to_csv(SAVE_DIR, index = False)\n",
    "        temp_df[\"app\"] = app\n",
    "        df = pd.concat((df ,temp_df))\n",
    "df.to_csv(\"all_combined.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feedback'] = df['score'].apply(lambda x: 0 if x < 3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['content']\n",
    "y = df['feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1592, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words: \n",
      "1514\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words: \")\n",
    "print(len(np.unique(np.hstack(X))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feedback\n",
       "1    819\n",
       "0    773\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def preprocess(text):\n",
    "        doc = nlp(text)\n",
    "        filtered_tokens = []\n",
    "        for token in doc:\n",
    "                if token.is_stop or token.is_punct:\n",
    "                        continue\n",
    "                filtered_tokens.append(token.lemma_)\n",
    "        \n",
    "        return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['preprocessed_text'] = df['content'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                           waste time\n",
       "1    extremely impressed Mobicip Customer Service q...\n",
       "2                                             friendly\n",
       "3                                                 work\n",
       "4                                      Invades privacy\n",
       "Name: preprocessed_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preprocessed_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['preprocessed_text'], \n",
    "    df['feedback'],\n",
    "    test_size = 0.2,\n",
    "    random_state = 348,\n",
    "    stratify = df['feedback']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "Tokenizer = TfidfVectorizer()\n",
    "X_train_2 = Tokenizer.fit_transform(X_train).toarray()\n",
    "X_test_2 = Tokenizer.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1273, 2763)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "ann_model = Sequential([\n",
    "        Dense(units = 128, input_dim = X_train_2.shape[1], activation = 'relu'),\n",
    "        Dense(units = 64, activation = 'relu'),\n",
    "        Dense(units = 1, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "ann_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "9/9 [==============================] - 1s 19ms/step - loss: 0.6892 - acc: 0.5249 - val_loss: 0.6862 - val_acc: 0.4844\n",
      "Epoch 2/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.6635 - acc: 0.7162 - val_loss: 0.6641 - val_acc: 0.5938\n",
      "Epoch 3/10\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 0.6123 - acc: 0.8306 - val_loss: 0.6188 - val_acc: 0.6797\n",
      "Epoch 4/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.5196 - acc: 0.9092 - val_loss: 0.5435 - val_acc: 0.7266\n",
      "Epoch 5/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.3967 - acc: 0.9371 - val_loss: 0.4669 - val_acc: 0.7734\n",
      "Epoch 6/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.2758 - acc: 0.9607 - val_loss: 0.4084 - val_acc: 0.8047\n",
      "Epoch 7/10\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 0.1839 - acc: 0.9686 - val_loss: 0.3973 - val_acc: 0.8047\n",
      "Epoch 8/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.1259 - acc: 0.9738 - val_loss: 0.4098 - val_acc: 0.7891\n",
      "Epoch 9/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0910 - acc: 0.9808 - val_loss: 0.4453 - val_acc: 0.7812\n",
      "Epoch 10/10\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 0.0704 - acc: 0.9843 - val_loss: 0.4669 - val_acc: 0.7734\n"
     ]
    }
   ],
   "source": [
    "history = ann_model.fit(X_train_2, y_train, batch_size=128, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 1ms/step - loss: 0.4445 - acc: 0.8119\n"
     ]
    }
   ],
   "source": [
    "ann_score = ann_model.evaluate(X_test_2, y_test, verbose = 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
