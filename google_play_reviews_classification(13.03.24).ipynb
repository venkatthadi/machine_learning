{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dLBpCsPAWJl"
      },
      "source": [
        "## Prerequisite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MGU-RecRw4i",
        "outputId": "a77c02c2-fba2-40ae-d94a-19226820161c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: google-play-scraper in /home/user/.local/lib/python3.8/site-packages (1.2.6)\n",
            "Requirement already satisfied: nltk in /home/user/.local/lib/python3.8/site-packages (3.8.1)\n",
            "Requirement already satisfied: joblib in /home/user/.local/lib/python3.8/site-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /home/user/.local/lib/python3.8/site-packages (from nltk) (4.66.2)\n",
            "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (7.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/user/.local/lib/python3.8/site-packages (from nltk) (2023.12.25)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.13.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (479.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 479.6 MB 39 kB/s  eta 0:00:01     |████████████████████▊           | 310.1 MB 2.6 MB/s eta 0:01:07███████▎| 468.0 MB 1.6 MB/s eta 0:00:08\n",
            "\u001b[?25hCollecting h5py>=2.9.0\n",
            "  Downloading h5py-3.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.8 MB 1.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting flatbuffers>=23.1.21\n",
            "  Downloading flatbuffers-24.3.7-py2.py3-none-any.whl (26 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
            "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[K     |████████████████████████████████| 294 kB 1.1 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflow) (1.14.0)\n",
            "Collecting keras<2.14,>=2.13.1\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 895 kB/s eta 0:00:01\n",
            "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: packaging in /home/user/.local/lib/python3.8/site-packages (from tensorflow) (23.2)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.62.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 2.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard<2.14,>=2.13\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 1.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1; platform_machine != \"arm64\" or platform_system != \"Darwin\"\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4 MB 2.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[K     |████████████████████████████████| 440 kB 2.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.16.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 1.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 2.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting absl-py>=1.0.0\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 2.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting libclang>=13.0.0\n",
            "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.9 MB 2.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting typing-extensions<4.6.0,>=3.6.6\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting numpy<=1.24.3,>=1.22\n",
            "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3 MB 2.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (0.34.2)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 3.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.22.0)\n",
            "Collecting werkzeug>=1.0.1\n",
            "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 2.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.28.2-py2.py3-none-any.whl (186 kB)\n",
            "\u001b[K     |████████████████████████████████| 186 kB 3.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.4.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in /home/user/.local/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (7.0.2)\n",
            "Collecting MarkupSafe>=2.1.1\n",
            "  Downloading MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/lib/python3/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/user/.local/lib/python3.8/site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.14,>=2.13->tensorflow) (3.17.0)\n",
            "Installing collected packages: numpy, h5py, flatbuffers, protobuf, keras, gast, termcolor, grpcio, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard-data-server, markdown, MarkupSafe, werkzeug, tensorboard, tensorflow-io-gcs-filesystem, astunparse, google-pasta, tensorflow-estimator, wrapt, opt-einsum, libclang, typing-extensions, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.4\n",
            "    Uninstalling numpy-1.24.4:\n",
            "      Successfully uninstalled numpy-1.24.4\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.10.0\n",
            "    Uninstalling typing-extensions-4.10.0:\n",
            "      Successfully uninstalled typing-extensions-4.10.0\n",
            "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.7 gast-0.4.0 google-auth-2.28.2 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.62.1 h5py-3.10.0 keras-2.13.1 libclang-16.0.6 markdown-3.5.2 numpy-1.24.3 opt-einsum-3.3.0 protobuf-4.25.3 requests-oauthlib-1.4.0 tensorboard-2.13.0 tensorboard-data-server-0.7.2 tensorflow-2.13.1 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.4.0 typing-extensions-4.5.0 werkzeug-3.0.1 wrapt-1.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install google-play-scraper\n",
        "!pip install nltk\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1kZLtPStP_t"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Swn0udqsR2r6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-14 10:22:12.943652: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-14 10:22:12.988717: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2024-03-14 10:22:12.989544: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-14 10:22:13.978333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ],
      "source": [
        "from google_play_scraper import app, Sort, reviews_all\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json, os, uuid\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.text import one_hot, Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dropout, Dense\n",
        "from keras.layers import Flatten, GlobalMaxPooling1D, Embedding, Conv1D, LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WH2wrBRD3Qi",
        "outputId": "6d55d78e-09b5-4174-c16b-c687ce239cb1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /home/user/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eXG20BEtUOG"
      },
      "source": [
        "Collect google play reviews using google-play-scraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "iegri5bcR_0e"
      },
      "outputs": [],
      "source": [
        "g_reviews = reviews_all(\n",
        "        \"mobicip.com.safeBrowserff\", # application ID\n",
        "        sleep_milliseconds=0, # defaults to 0\n",
        "        lang='en', # defaults to 'en'\n",
        "        country='us', # defaults to 'us'\n",
        "        sort=Sort.NEWEST, # defaults to Sort.MOST_RELEVANT\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zx9cqWB1uGHW"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zz08SUGtbnV"
      },
      "source": [
        "### Arrange data into dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dyiLxb_2SMck"
      },
      "outputs": [],
      "source": [
        "g_df = pd.DataFrame(np.array(g_reviews),columns=['review'])\n",
        "g_df2 = g_df.join(pd.DataFrame(g_df.pop('review').tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xqhaHsohTHaO"
      },
      "outputs": [],
      "source": [
        "g_df2.drop(columns={'userImage', 'reviewCreatedVersion'},inplace = True) # drop unnecessary columns\n",
        "g_df2.rename(columns= {'score': 'rating','userName': 'user_name', 'reviewId': 'review_id', 'content': 'review_description', 'at': 'review_date', 'replyContent': 'developer_response', 'repliedAt': 'developer_response_date', 'thumbsUpCount': 'thumbs_up'},inplace = True)\n",
        "# g_df2.insert(loc=0, column='source', value='Google Play')\n",
        "# g_df2.insert(loc=3, column='review_title', value=None)\n",
        "# g_df2['laguage_code'] = 'en'\n",
        "# g_df2['country_code'] = 'us'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "465zh3akVH94",
        "outputId": "220e1aa5-2369-4b1d-f5cc-7b8f9e6fd235"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(199, 9)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g_df2.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uNJiShJiVX9N"
      },
      "outputs": [],
      "source": [
        "# storing into a .csv file for future use\n",
        "\n",
        "g_df2.to_csv('play_reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vBKxUUOZQA7",
        "outputId": "e87cc3ec-1016-4ab2-cc08-cc1c90d4eeea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "rating\n",
              "1    124\n",
              "5     51\n",
              "2     14\n",
              "3      6\n",
              "4      4\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g_df2['rating'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "fJyfpSVCqI4_",
        "outputId": "03b3571a-4d3a-4a96-d345-a5acd7baa99e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>user_name</th>\n",
              "      <th>review_description</th>\n",
              "      <th>rating</th>\n",
              "      <th>thumbs_up</th>\n",
              "      <th>review_date</th>\n",
              "      <th>developer_response</th>\n",
              "      <th>developer_response_date</th>\n",
              "      <th>appVersion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>9b96fe32-d8bc-448f-bf37-eaa79506a6b6</td>\n",
              "      <td>Tugsan Topcuoglu</td>\n",
              "      <td>Waste of time</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-03-06 03:58:33</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2.2.8_r824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>d5cb1046-ee6d-4fc5-ac03-c873e6ded9df</td>\n",
              "      <td>Roxanne LaRusso</td>\n",
              "      <td>I am extremely impressed with Mobicip's Custom...</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-02-26 19:45:52</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fe265e2e-117d-42b2-b8ca-63fc24e551b3</td>\n",
              "      <td>Williamcadder Mutevedzi</td>\n",
              "      <td>Friendly</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-02-24 22:13:47</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>f44146dc-a7a3-445e-8183-6b153f482555</td>\n",
              "      <td>Justyna D</td>\n",
              "      <td>Does not work</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-02-22 01:06:51</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2.2.7_r812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>69bc7a7b-1cca-409f-96b1-8b19288ab427</td>\n",
              "      <td>Liam Whitwam</td>\n",
              "      <td>Invades privacy</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2024-02-13 09:18:45</td>\n",
              "      <td>None</td>\n",
              "      <td>NaT</td>\n",
              "      <td>2.2.4_r791</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              review_id                user_name  \\\n",
              "0  9b96fe32-d8bc-448f-bf37-eaa79506a6b6         Tugsan Topcuoglu   \n",
              "1  d5cb1046-ee6d-4fc5-ac03-c873e6ded9df          Roxanne LaRusso   \n",
              "2  fe265e2e-117d-42b2-b8ca-63fc24e551b3  Williamcadder Mutevedzi   \n",
              "3  f44146dc-a7a3-445e-8183-6b153f482555                Justyna D   \n",
              "4  69bc7a7b-1cca-409f-96b1-8b19288ab427             Liam Whitwam   \n",
              "\n",
              "                                  review_description  rating  thumbs_up  \\\n",
              "0                                      Waste of time       1          0   \n",
              "1  I am extremely impressed with Mobicip's Custom...       5          0   \n",
              "2                                           Friendly       5          0   \n",
              "3                                      Does not work       1          0   \n",
              "4                                    Invades privacy       1          0   \n",
              "\n",
              "          review_date developer_response developer_response_date  appVersion  \n",
              "0 2024-03-06 03:58:33               None                     NaT  2.2.8_r824  \n",
              "1 2024-02-26 19:45:52               None                     NaT        None  \n",
              "2 2024-02-24 22:13:47               None                     NaT        None  \n",
              "3 2024-02-22 01:06:51               None                     NaT  2.2.7_r812  \n",
              "4 2024-02-13 09:18:45               None                     NaT  2.2.4_r791  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g_df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP3iRlfVvZ3e"
      },
      "source": [
        "### Establishing data (X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "mg2lE76qAowu"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/play_reviews.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[18], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read data from csv\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/content/play_reviews.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1662\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1663\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1664\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1665\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1666\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1668\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/play_reviews.csv'"
          ]
        }
      ],
      "source": [
        "# read data from csv\n",
        "\n",
        "df = pd.read_csv('/content/play_reviews.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dBuJ3Qy0BFSL"
      },
      "outputs": [],
      "source": [
        "# create new column for binary classification\n",
        "\n",
        "df['feedback'] = df['rating'].apply(lambda x: 0 if x < 3 else 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "UPuInsCFsPOU"
      },
      "outputs": [],
      "source": [
        "# declare variables\n",
        "\n",
        "X = df['review_description']\n",
        "Y = df['feedback']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8dkv3WPrzi7",
        "outputId": "8763feea-5de7-431d-bd91-26135d69ed1e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of words: \n",
            "593\n"
          ]
        }
      ],
      "source": [
        "# get count of vocabulary\n",
        "\n",
        "print(\"Number of words: \")\n",
        "print(len(np.unique(np.hstack(X))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JEy4SxuEBMR",
        "outputId": "dbd43a38-40d5-4db0-9f71-a22d38fd5b52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# check if any null values are present in reviews part\n",
        "\n",
        "X.isnull().values.any()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGUq3vk9FF6r"
      },
      "source": [
        "### Preparing data for embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gfa2scc6FFYM"
      },
      "outputs": [],
      "source": [
        "stopwords_list = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "WetEZkZzFPg-"
      },
      "outputs": [],
      "source": [
        "class CustomPreprocess():\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def preprocess_text(self,sen):\n",
        "        sen = sen.lower()\n",
        "\n",
        "        # # Remove html tags\n",
        "        # sentence = remove_tags(sen)\n",
        "\n",
        "        # Remove punctuations and numbers\n",
        "        sen = re.sub('[^a-zA-Z]', ' ', sen)\n",
        "\n",
        "        # Single character removal\n",
        "        sen = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sen)\n",
        "\n",
        "        # Remove multiple spaces\n",
        "        sen = re.sub(r'\\s+', ' ', sen)\n",
        "\n",
        "        # Remove Stopwords\n",
        "        pattern = re.compile(r'\\b(' + r'|'.join(stopwords_list) + r')\\b\\s*')\n",
        "        sen = pattern.sub('', sen)\n",
        "\n",
        "        return sen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_mzD3AaYFpbu"
      },
      "outputs": [],
      "source": [
        "# define preprocessing\n",
        "\n",
        "custom = CustomPreprocess()\n",
        "X_new = []\n",
        "sentences = list(X)\n",
        "for sen in sentences:\n",
        "  X_new.append(custom.preprocess_text(sen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TE6Kjo2GIpjh",
        "outputId": "cdb71b97-5a3f-4c6d-a864-3490227493d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(X_new[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "0TYra4J_tMbx"
      },
      "outputs": [],
      "source": [
        "# split data into training and testing sets\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, test_size = 0.25)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTTjGndCAJkA"
      },
      "source": [
        "## Word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VKP2_AFnAPjR"
      },
      "outputs": [],
      "source": [
        "# tokenize the sentences into arrays of words\n",
        "\n",
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(X_new)\n",
        "\n",
        "X_train = word_tokenizer.texts_to_sequences(X_train)\n",
        "X_test = word_tokenizer.texts_to_sequences(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qMEx4HyJpHs",
        "outputId": "26f8d352-ada3-40a1-aef4-b82ebf7b996b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2242"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_length = len(word_tokenizer.word_index) + 1\n",
        "\n",
        "vocab_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1V37IJNLKJCQ"
      },
      "outputs": [],
      "source": [
        "# Padding all reviews to fixed length 100\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen = 100)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen = 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "6NuG3kXjNx5R"
      },
      "outputs": [],
      "source": [
        "# Load GloVe word embeddings and create an Embeddings Dictionary\n",
        "\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "\n",
        "embeddings_dictionary = dict()\n",
        "glove_file = open('/content/drive/MyDrive/Datasets/glove.6B.100d.txt', encoding=\"utf8\")\n",
        "\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "\n",
        "glove_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "E4yLKGwVNytv"
      },
      "outputs": [],
      "source": [
        "# Create Embedding Matrix having 100 columns\n",
        "# Containing 100-dimensional GloVe word embeddings for all words in our corpus.\n",
        "\n",
        "embedding_matrix = zeros((vocab_length, 100))\n",
        "\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuJuVBPDvxBc"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H4i_qFoOMlf"
      },
      "source": [
        "### ANN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dYcPJ2Gvv0N",
        "outputId": "be3e7aab-556b-42f7-8bac-b41a5f20becb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          224200    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 10000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 10001     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 234201 (914.85 KB)\n",
            "Trainable params: 10001 (39.07 KB)\n",
            "Non-trainable params: 224200 (875.78 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# simple neural network\n",
        "\n",
        "ann_model = Sequential([\n",
        "    Embedding(vocab_length, 100, weights = [embedding_matrix], input_length = 100, trainable = False),\n",
        "    Flatten(),\n",
        "    Dense(1, activation = 'sigmoid'),\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "\n",
        "ann_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "\n",
        "print(ann_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ1rtx1YPuMn",
        "outputId": "0291a37c-43f6-498a-834c-339dbdb6c305"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3/3 - 2s - loss: 0.7184 - acc: 0.4986 - val_loss: 0.6603 - val_acc: 0.6556 - 2s/epoch - 546ms/step\n",
            "Epoch 2/5\n",
            "3/3 - 0s - loss: 0.6390 - acc: 0.6387 - val_loss: 0.6391 - val_acc: 0.7000 - 96ms/epoch - 32ms/step\n",
            "Epoch 3/5\n",
            "3/3 - 0s - loss: 0.5859 - acc: 0.7703 - val_loss: 0.6262 - val_acc: 0.7444 - 106ms/epoch - 35ms/step\n",
            "Epoch 4/5\n",
            "3/3 - 0s - loss: 0.5490 - acc: 0.8039 - val_loss: 0.6136 - val_acc: 0.7667 - 96ms/epoch - 32ms/step\n",
            "Epoch 5/5\n",
            "3/3 - 0s - loss: 0.5201 - acc: 0.8487 - val_loss: 0.5988 - val_acc: 0.7667 - 138ms/epoch - 46ms/step\n"
          ]
        }
      ],
      "source": [
        "# train the model\n",
        "\n",
        "ann_history = ann_model.fit(X_train, Y_train, batch_size = 128, epochs = 5, verbose = 2, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su2qpnvMQMCX",
        "outputId": "754633d0-06da-49cc-e859-b50be79fba82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 3ms/step - loss: 0.6588 - acc: 0.7133\n"
          ]
        }
      ],
      "source": [
        "# get the loss and accuracy\n",
        "\n",
        "ann_score = ann_model.evaluate(X_test, Y_test, verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mYTTVKdXUBw"
      },
      "source": [
        "### CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "g6Ryr4a-XVov"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Conv1D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWYBLYTEXebe",
        "outputId": "920c0dca-1152-411e-f78f-dfc41d8767dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 100, 100)          224200    \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 96, 128)           64128     \n",
            "                                                                 \n",
            " global_max_pooling1d (Glob  (None, 128)               0         \n",
            " alMaxPooling1D)                                                 \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 288457 (1.10 MB)\n",
            "Trainable params: 64257 (251.00 KB)\n",
            "Non-trainable params: 224200 (875.78 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# define the model\n",
        "\n",
        "cnn_model = Sequential([\n",
        "    Embedding(vocab_length, 100, weights = [embedding_matrix], input_length = 100, trainable = False),\n",
        "    Conv1D(128, 5, activation = 'relu'),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "\n",
        "cnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "\n",
        "print(cnn_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaLamX5KZr-H",
        "outputId": "8df2301e-fac5-4a96-8974-21abdd3f29fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3/3 - 1s - loss: 0.6915 - acc: 0.5602 - val_loss: 0.5871 - val_acc: 0.7111 - 1s/epoch - 395ms/step\n",
            "Epoch 2/5\n",
            "3/3 - 0s - loss: 0.5368 - acc: 0.8235 - val_loss: 0.5383 - val_acc: 0.8333 - 286ms/epoch - 95ms/step\n",
            "Epoch 3/5\n",
            "3/3 - 0s - loss: 0.4439 - acc: 0.8964 - val_loss: 0.4941 - val_acc: 0.8000 - 293ms/epoch - 98ms/step\n",
            "Epoch 4/5\n",
            "3/3 - 0s - loss: 0.3757 - acc: 0.9076 - val_loss: 0.4617 - val_acc: 0.8444 - 292ms/epoch - 97ms/step\n",
            "Epoch 5/5\n",
            "3/3 - 0s - loss: 0.3275 - acc: 0.9524 - val_loss: 0.4416 - val_acc: 0.8333 - 311ms/epoch - 104ms/step\n"
          ]
        }
      ],
      "source": [
        "cnn_history = cnn_model.fit(X_train, Y_train, batch_size = 128, epochs = 5, verbose = 2, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vqmoIjdaJIx",
        "outputId": "6c0a8d7d-7c43-4b85-edb9-56ae95b6c18b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 19ms/step - loss: 0.4937 - acc: 0.7933\n"
          ]
        }
      ],
      "source": [
        "cnn_score = cnn_model.evaluate(X_test, Y_test, verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21JzY7bhamEZ"
      },
      "source": [
        "### LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "YiaFVuGUaSYj"
      },
      "outputs": [],
      "source": [
        "from keras.layers import LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbxdS3pSarE1",
        "outputId": "4c1c6def-d044-485d-f499-ca26d54accf5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 100, 100)          224200    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               117248    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 341577 (1.30 MB)\n",
            "Trainable params: 117377 (458.50 KB)\n",
            "Non-trainable params: 224200 (875.78 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# define the model\n",
        "\n",
        "rnn_model = Sequential([\n",
        "    Embedding(vocab_length, 100, weights = [embedding_matrix], input_length = 100, trainable = False),\n",
        "    LSTM(128),\n",
        "    Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "# compile the model\n",
        "\n",
        "rnn_model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc'])\n",
        "\n",
        "print(rnn_model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmp3Qj2gbJbV",
        "outputId": "43a41526-cbe6-441e-cc12-eeee14386395"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "3/3 - 5s - loss: 0.6923 - acc: 0.5574 - val_loss: 0.6872 - val_acc: 0.6333 - 5s/epoch - 2s/step\n",
            "Epoch 2/5\n",
            "3/3 - 1s - loss: 0.6855 - acc: 0.5966 - val_loss: 0.6781 - val_acc: 0.6444 - 943ms/epoch - 314ms/step\n",
            "Epoch 3/5\n",
            "3/3 - 1s - loss: 0.6774 - acc: 0.5966 - val_loss: 0.6605 - val_acc: 0.6444 - 934ms/epoch - 311ms/step\n",
            "Epoch 4/5\n",
            "3/3 - 1s - loss: 0.6710 - acc: 0.5994 - val_loss: 0.6509 - val_acc: 0.6444 - 923ms/epoch - 308ms/step\n",
            "Epoch 5/5\n",
            "3/3 - 1s - loss: 0.6690 - acc: 0.5994 - val_loss: 0.6513 - val_acc: 0.6444 - 977ms/epoch - 326ms/step\n"
          ]
        }
      ],
      "source": [
        "rnn_history = rnn_model.fit(X_train, Y_train, batch_size = 128, epochs = 5, verbose = 2, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQBpZF-ubVZm",
        "outputId": "57e46ac7-5fd1-42a1-84f7-669b63423573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 1s 110ms/step - loss: 0.6976 - acc: 0.5400\n"
          ]
        }
      ],
      "source": [
        "rnn_score = rnn_model.evaluate(X_test, Y_test, verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHs6CoSsvThb"
      },
      "source": [
        "## Testing models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qGEwp-Jv9yJ",
        "outputId": "fceb077b-a2f9-4525-94d0-aed318473f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "[[0.4553344 ]\n",
            " [0.46020716]\n",
            " [0.41867155]]\n"
          ]
        }
      ],
      "source": [
        "sen = [\n",
        "    \"i liked it\",\n",
        "    \"nice\",\n",
        "    \"i was buggy and lagging\"\n",
        "    ]\n",
        "\n",
        "processed_data = []\n",
        "\n",
        "for s in sen:\n",
        "  processed_data.append(custom.preprocess_text(s))\n",
        "\n",
        "processed_data = word_tokenizer.texts_to_sequences(processed_data)\n",
        "processed_data = pad_sequences(processed_data, padding = 'post', maxlen = 100)\n",
        "\n",
        "output = cnn_model.predict(processed_data)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cR4Uj1ZR2Gae"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
